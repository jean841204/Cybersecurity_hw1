import streamlit as st
import numpy as np
import pandas as pd
import sys
import os

# æ·»åŠ srcç›®éŒ„åˆ°Pythonè·¯å¾‘
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from data_generator import DataGenerator
from model_trainer import LinearRegressionModel
from evaluator import ModelEvaluator
from visualizer import RegressionVisualizer

# é é¢é…ç½®
st.set_page_config(
    page_title="Linear Regression Analysis System",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šç¾©CSS
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #1f77b4, #ff7f0e);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #1f77b4;
        margin-bottom: 1rem;
    }
    .sidebar-header {
        background: #e3f2fd;
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 1rem;
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)

def init_session_state():
    """åˆå§‹åŒ–session state"""
    if 'data_generated' not in st.session_state:
        st.session_state.data_generated = False
    if 'model_trained' not in st.session_state:
        st.session_state.model_trained = False
    if 'data_generator' not in st.session_state:
        st.session_state.data_generator = DataGenerator()
    if 'model' not in st.session_state:
        st.session_state.model = LinearRegressionModel()
    if 'evaluator' not in st.session_state:
        st.session_state.evaluator = ModelEvaluator()
    if 'visualizer' not in st.session_state:
        st.session_state.visualizer = RegressionVisualizer()

def main():
    """ä¸»æ‡‰ç”¨å‡½æ•¸"""
    init_session_state()

    # ä¸»æ¨™é¡Œ
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“Š Linear Regression Analysis System</h1>
        <p>Interactive Linear Regression Analysis Tool Based on CRISP-DM Process</p>
    </div>
    """, unsafe_allow_html=True)

    # å´é‚Šæ¬„æ§åˆ¶é¢æ¿
    with st.sidebar:
        st.markdown("""
        <div class="sidebar-header">
            <h2>ğŸ›ï¸ Parameter Control Panel</h2>
        </div>
        """, unsafe_allow_html=True)

        # Parameters
        st.subheader("Parameters")

        n_points = st.slider(
            "Number of data points (n)",
            min_value=10,
            max_value=1000,
            value=100,
            step=10,
            help="Number of data points to generate"
        )

        slope = st.slider(
            "Coefficient 'a' (y = ax + b + noise)",
            min_value=-10.0,
            max_value=10.0,
            value=2.0,
            step=0.1,
            help="Slope parameter in linear equation"
        )

        noise_variance = st.slider(
            "Noise Variance (var)",
            min_value=0.0,
            max_value=5000.0,
            value=1000.0,
            step=100.0,
            help="Variance of Gaussian noise N(0, variance)"
        )

        noise_level = np.sqrt(noise_variance)  # Convert variance to std dev
        intercept = 30.0  # Fixed intercept as per requirements
        test_size = 0.2  # Fixed test size
        use_scaling = False  # Fixed scaling
        random_seed = 42  # Fixed seed

        # è‡ªå‹•ç”Ÿæˆå’Œè¨“ç·´ (å¯¦æ™‚æ›´æ–°ï¼Œç„¡éœ€æŒ‰éˆ•)
        # ç•¶åƒæ•¸æ”¹è®Šæ™‚è‡ªå‹•æ›´æ–°
        if not hasattr(st.session_state, 'last_params') or st.session_state.last_params != (n_points, slope, noise_variance):
            generate_and_train_automatically(slope, intercept, n_points, noise_level, random_seed, test_size, use_scaling)
            st.session_state.last_params = (n_points, slope, noise_variance)

    # ä¸»å…§å®¹å€åŸŸ - ç°¡åŒ–ç‰ˆæœ¬
    if st.session_state.model_trained:
        # ç›´æ¥é¡¯ç¤ºæ ¸å¿ƒåœ–è¡¨
        show_simple_regression_plot()

        # æ–°å¢åŠŸèƒ½å€åŸŸ
        col1, col2 = st.columns(2)

        with col1:
            show_model_coefficients()

        with col2:
            show_top_outliers_table()
    else:
        st.info("ğŸ‘ˆ Please adjust parameters to see the regression plot")

def generate_and_train_automatically(slope, intercept, n_points, noise_level, random_seed, test_size, use_scaling):
    """è‡ªå‹•ç”Ÿæˆæ•¸æ“šä¸¦è¨“ç·´æ¨¡å‹"""
    try:
        # ç”Ÿæˆæ•¸æ“š
        x_data, y_data = st.session_state.data_generator.generate_linear_data(
            n_points=n_points,
            slope=slope,
            intercept=intercept,
            noise_level=noise_level,
            random_seed=random_seed
        )

        st.session_state.x_data = x_data
        st.session_state.y_data = y_data
        st.session_state.data_generated = True

        # è‡ªå‹•è¨“ç·´æ¨¡å‹
        st.session_state.model = LinearRegressionModel(
            test_size=test_size,
            random_state=42
        )

        # æº–å‚™æ•¸æ“š
        st.session_state.model.prepare_data(
            st.session_state.x_data,
            st.session_state.y_data,
            use_scaling=use_scaling
        )

        # è¨“ç·´æ¨¡å‹
        train_result = st.session_state.model.train_model()

        # ç”Ÿæˆé æ¸¬
        predictions = st.session_state.model.make_predictions()

        # è¨ˆç®—è©•ä¼°æŒ‡æ¨™
        metrics = st.session_state.evaluator.calculate_metrics(
            np.concatenate([predictions['train_actual'], predictions['test_actual']]),
            np.concatenate([predictions['train_predictions'], predictions['test_predictions']])
        )

        # å­˜å„²çµæœ
        st.session_state.train_result = train_result
        st.session_state.predictions = predictions
        st.session_state.metrics = metrics
        st.session_state.model_trained = True

    except Exception as e:
        st.error(f"âŒ Error: {str(e)}")

def show_simple_regression_plot():
    """é¡¯ç¤ºç°¡åŒ–çš„å›æ­¸åœ–è¡¨"""
    # Get outliers for visualization
    all_actual = np.concatenate([st.session_state.predictions['train_actual'],
                               st.session_state.predictions['test_actual']])
    all_pred = np.concatenate([st.session_state.predictions['train_predictions'],
                             st.session_state.predictions['test_predictions']])
    all_x = np.concatenate([st.session_state.predictions['train_features'],
                          st.session_state.predictions['test_features']])

    outliers_info = st.session_state.evaluator.get_top_outliers(
        all_actual, all_pred, all_x, n_outliers=5
    )

    # Create regression line data
    x_line = np.linspace(np.min(st.session_state.x_data), np.max(st.session_state.x_data), 100)
    y_line = st.session_state.train_result['slope'] * x_line + st.session_state.train_result['intercept']

    # Simple regression plot
    fig = st.session_state.visualizer.plot_scatter_with_regression(
        st.session_state.x_data,
        st.session_state.y_data,
        y_pred=y_line,
        x_pred=x_line,
        title="Linear Regression with Top 5 Outliers",
        show_equation=True,
        equation=f"y = {st.session_state.train_result['slope']:.4f}x + {st.session_state.train_result['intercept']:.4f}",
        r2_score=st.session_state.metrics['r2_score'],
        outliers_info=outliers_info
    )

    st.plotly_chart(fig, use_container_width=True)

def show_model_coefficients():
    """é¡¯ç¤ºæ¨¡å‹ä¿‚æ•¸"""
    st.subheader("Model Coefficients")

    coefficients_df = pd.DataFrame({
        'Coefficient': ['Slope (a)', 'Intercept (b)', 'RÂ² Score'],
        'True Value': [
            f"{st.session_state.data_generator.true_slope:.4f}",
            f"{st.session_state.data_generator.true_intercept:.4f}",
            "-"
        ],
        'Estimated Value': [
            f"{st.session_state.train_result['slope']:.4f}",
            f"{st.session_state.train_result['intercept']:.4f}",
            f"{st.session_state.metrics['r2_score']:.4f}"
        ]
    })

    st.dataframe(coefficients_df, use_container_width=True, hide_index=True)

def show_top_outliers_table():
    """é¡¯ç¤ºTop 5ç•°å¸¸å€¼è¡¨æ ¼"""
    st.subheader("Top 5 Outliers")

    # ç²å–ç•°å¸¸å€¼æ•¸æ“š
    all_actual = np.concatenate([st.session_state.predictions['train_actual'],
                               st.session_state.predictions['test_actual']])
    all_pred = np.concatenate([st.session_state.predictions['train_predictions'],
                             st.session_state.predictions['test_predictions']])
    all_x = np.concatenate([st.session_state.predictions['train_features'],
                          st.session_state.predictions['test_features']])

    outliers_info = st.session_state.evaluator.get_top_outliers(
        all_actual, all_pred, all_x, n_outliers=5
    )

    # å‰µå»ºç•°å¸¸å€¼è¡¨æ ¼
    outliers_df = pd.DataFrame({
        'Rank': [f"O{i+1}" for i in range(len(outliers_info['x_values']))],
        'X Value': [f"{x:.3f}" for x in outliers_info['x_values']],
        'Y Value': [f"{y:.3f}" for y in outliers_info['y_values']],
        'Residual': [f"{r:.3f}" for r in outliers_info['residuals']],
        'Score': [f"{s:.3f}" for s in outliers_info['scores']]
    })

    st.dataframe(outliers_df, use_container_width=True, hide_index=True)

def show_data_overview():
    """Show data overview"""
    st.subheader("ğŸ“Š Data Overview and Exploratory Analysis")

    # ç²å–æ•¸æ“šæ‘˜è¦
    summary = st.session_state.data_generator.data_summary()
    quality_report = st.session_state.data_generator.check_data_quality()

    # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            "Data Points",
            summary['data_points'],
            help="Total number of generated data points"
        )

    with col2:
        st.metric(
            "Correlation",
            f"{summary['correlation']:.4f}",
            help="Pearson correlation coefficient between X and Y"
        )

    with col3:
        st.metric(
            "True Slope",
            f"{summary['parameters']['true_slope']:.2f}",
            help="True slope used when generating data"
        )

    with col4:
        st.metric(
            "Noise Level",
            f"{summary['parameters']['noise_level']:.2f}",
            help="Standard deviation of added Gaussian noise"
        )

    # æ•¸æ“šè¦–è¦ºåŒ–
    col1, col2 = st.columns([2, 1])

    with col1:
        # æ•£é»åœ–
        fig = st.session_state.visualizer.plot_scatter_with_regression(
            st.session_state.x_data,
            st.session_state.y_data,
            title="åŸå§‹æ•¸æ“šæ•£é»åœ–",
            x_label="X",
            y_label="Y"
        )
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        # æ•¸æ“šçµ±è¨ˆè¡¨
        st.subheader("çµ±è¨ˆæ‘˜è¦")

        stats_df = pd.DataFrame({
            'X': [
                summary['x_statistics']['mean'],
                summary['x_statistics']['std'],
                summary['x_statistics']['min'],
                summary['x_statistics']['max']
            ],
            'Y': [
                summary['y_statistics']['mean'],
                summary['y_statistics']['std'],
                summary['y_statistics']['min'],
                summary['y_statistics']['max']
            ]
        }, index=['å¹³å‡å€¼', 'æ¨™æº–å·®', 'æœ€å°å€¼', 'æœ€å¤§å€¼'])

        st.dataframe(stats_df, use_container_width=True)

        # æ•¸æ“šå“è³ªå ±å‘Š
        st.subheader("æ•¸æ“šå“è³ª")
        if quality_report['missing_values']['x_missing'] == 0 and quality_report['missing_values']['y_missing'] == 0:
            st.success("âœ… ç„¡ç¼ºå¤±å€¼")
        else:
            st.warning(f"âš ï¸ ç™¼ç¾ç¼ºå¤±å€¼: X({quality_report['missing_values']['x_missing']}), Y({quality_report['missing_values']['y_missing']})")

        outlier_percentage = (quality_report['outliers']['x_outliers'] + quality_report['outliers']['y_outliers']) / (2 * summary['data_points']) * 100
        if outlier_percentage < 5:
            st.success(f"âœ… ç•°å¸¸å€¼æ¯”ä¾‹: {outlier_percentage:.1f}%")
        else:
            st.warning(f"âš ï¸ ç•°å¸¸å€¼æ¯”ä¾‹: {outlier_percentage:.1f}%")

    # æ•¸æ“šåˆ†ä½ˆåˆ†æ
    st.subheader("æ•¸æ“šåˆ†ä½ˆåˆ†æ")
    fig_dist = st.session_state.visualizer.plot_data_distribution(
        st.session_state.x_data,
        st.session_state.y_data
    )
    st.plotly_chart(fig_dist, use_container_width=True)

def show_model_results():
    """Show model results"""
    # å›æ­¸åˆ†æè¡¨æ ¼åœ¨æœ€ä¸Šé¢
    st.subheader("ğŸ“Š Regression Analysis Results")

    # å›æ­¸æ–¹ç¨‹å¼
    equation = st.session_state.model.get_model_equation()
    st.info(f"ğŸ“ **Regression Equation**: {equation}")

    # æ¨¡å‹çµæœè¡¨æ ¼
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Model Parameters")
        params_df = pd.DataFrame({
            'Parameter': ['True Slope (a)', 'Estimated Slope', 'True Intercept (b)', 'Estimated Intercept'],
            'Value': [
                f"{st.session_state.data_generator.true_slope:.4f}",
                f"{st.session_state.train_result['slope']:.4f}",
                f"{st.session_state.data_generator.true_intercept:.4f}",
                f"{st.session_state.train_result['intercept']:.4f}"
            ]
        })
        st.dataframe(params_df, use_container_width=True, hide_index=True)

    with col2:
        st.subheader("Model Performance")
        metrics_df = pd.DataFrame({
            'Metric': ['RÂ² Score', 'RMSE', 'MAE', 'MAPE (%)'],
            'Value': [
                f"{st.session_state.metrics['r2_score']:.4f}",
                f"{st.session_state.metrics['rmse']:.4f}",
                f"{st.session_state.metrics['mae']:.4f}",
                f"{st.session_state.metrics['mape']:.2f}"
            ]
        })
        st.dataframe(metrics_df, use_container_width=True, hide_index=True)

    # ä¸»è¦è¦–è¦ºåŒ–
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ¯ å›æ­¸åˆ†æ", "ğŸ“Š æ®˜å·®åˆ†æ", "ğŸ” é æ¸¬å°æ¯”", "ğŸ“ˆ è©•ä¼°æŒ‡æ¨™"])

    with tab1:
        # Get outliers for visualization
        all_actual = np.concatenate([st.session_state.predictions['train_actual'],
                                   st.session_state.predictions['test_actual']])
        all_pred = np.concatenate([st.session_state.predictions['train_predictions'],
                                 st.session_state.predictions['test_predictions']])
        all_x = np.concatenate([st.session_state.predictions['train_features'],
                              st.session_state.predictions['test_features']])

        outliers_info = st.session_state.evaluator.get_top_outliers(
            all_actual, all_pred, all_x, n_outliers=5
        )

        # Create regression line data
        x_line = np.linspace(np.min(st.session_state.x_data), np.max(st.session_state.x_data), 100)
        y_line = st.session_state.train_result['slope'] * x_line + st.session_state.train_result['intercept']

        # Complete regression plot with outliers
        fig_regression = st.session_state.visualizer.plot_scatter_with_regression(
            st.session_state.x_data,
            st.session_state.y_data,
            y_pred=y_line,
            x_pred=x_line,
            title="Linear Regression Analysis with Top 5 Outliers",
            show_equation=True,
            equation=f"y = {st.session_state.train_result['slope']:.4f}x + {st.session_state.train_result['intercept']:.4f}",
            r2_score=st.session_state.metrics['r2_score'],
            outliers_info=outliers_info
        )
        st.plotly_chart(fig_regression, use_container_width=True)

        # æ¨¡å‹åƒæ•¸æ¯”è¼ƒ
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("çœŸå¯¦åƒæ•¸ vs ä¼°è¨ˆåƒæ•¸")
            comparison_df = pd.DataFrame({
                'çœŸå¯¦å€¼': [
                    st.session_state.data_generator.true_slope,
                    st.session_state.data_generator.true_intercept
                ],
                'ä¼°è¨ˆå€¼': [
                    st.session_state.train_result['slope'],
                    st.session_state.train_result['intercept']
                ],
                'èª¤å·®': [
                    abs(st.session_state.data_generator.true_slope - st.session_state.train_result['slope']),
                    abs(st.session_state.data_generator.true_intercept - st.session_state.train_result['intercept'])
                ]
            }, index=['æ–œç‡', 'æˆªè·'])
            st.dataframe(comparison_df, use_container_width=True)

        with col2:
            st.subheader("è¨“ç·´/æ¸¬è©¦é›†ä¿¡æ¯")
            train_size = len(st.session_state.predictions['train_actual'])
            test_size = len(st.session_state.predictions['test_actual'])

            info_df = pd.DataFrame({
                'æ•¸é‡': [train_size, test_size, train_size + test_size],
                'æ¯”ä¾‹': [f"{train_size/(train_size+test_size)*100:.1f}%",
                        f"{test_size/(train_size+test_size)*100:.1f}%", "100%"]
            }, index=['è¨“ç·´é›†', 'æ¸¬è©¦é›†', 'ç¸½è¨ˆ'])
            st.dataframe(info_df, use_container_width=True)

    with tab2:
        # æ®˜å·®åˆ†æ
        all_actual = np.concatenate([st.session_state.predictions['train_actual'],
                                   st.session_state.predictions['test_actual']])
        all_pred = np.concatenate([st.session_state.predictions['train_predictions'],
                                 st.session_state.predictions['test_predictions']])

        fig_residuals = st.session_state.visualizer.plot_residuals(
            all_actual, all_pred
        )
        st.plotly_chart(fig_residuals, use_container_width=True)

        # æ®˜å·®åˆ†æçµæœ
        residual_analysis = st.session_state.evaluator.residual_analysis(
            all_actual, all_pred
        )

        col1, col2 = st.columns(2)
        with col1:
            st.subheader("æ­£æ…‹æ€§æª¢é©—")
            normality = residual_analysis['normality_test']
            if normality['is_normal']:
                st.success("âœ… æ®˜å·®ç¬¦åˆæ­£æ…‹åˆ†ä½ˆ")
            else:
                st.warning("âš ï¸ æ®˜å·®åé›¢æ­£æ…‹åˆ†ä½ˆ")

            if normality['shapiro_p_value']:
                st.write(f"Shapiro-Wilk på€¼: {normality['shapiro_p_value']:.4f}")

        with col2:
            st.subheader("ç•°å¸¸å€¼æª¢æ¸¬")
            outliers = residual_analysis['outliers']
            st.write(f"ç•°å¸¸å€¼æ•¸é‡: {outliers['count']}")
            st.write(f"ç•°å¸¸å€¼æ¯”ä¾‹: {outliers['percentage']:.2f}%")

            if outliers['percentage'] < 5:
                st.success("âœ… ç•°å¸¸å€¼æ¯”ä¾‹æ­£å¸¸")
            else:
                st.warning("âš ï¸ ç•°å¸¸å€¼æ¯”ä¾‹åé«˜")

    with tab3:
        # é æ¸¬å°æ¯”
        fig_pred_vs_actual = st.session_state.visualizer.plot_predictions_vs_actual(
            all_actual, all_pred
        )
        st.plotly_chart(fig_pred_vs_actual, use_container_width=True)

        # é æ¸¬ç²¾åº¦åˆ†æ
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("è¨“ç·´é›†è¡¨ç¾")
            train_metrics = st.session_state.evaluator.calculate_metrics(
                st.session_state.predictions['train_actual'],
                st.session_state.predictions['train_predictions']
            )
            st.write(f"RÂ²: {train_metrics['r2_score']:.4f}")
            st.write(f"RMSE: {train_metrics['rmse']:.4f}")
            st.write(f"MAE: {train_metrics['mae']:.4f}")

        with col2:
            st.subheader("æ¸¬è©¦é›†è¡¨ç¾")
            test_metrics = st.session_state.evaluator.calculate_metrics(
                st.session_state.predictions['test_actual'],
                st.session_state.predictions['test_predictions']
            )
            st.write(f"RÂ²: {test_metrics['r2_score']:.4f}")
            st.write(f"RMSE: {test_metrics['rmse']:.4f}")
            st.write(f"MAE: {test_metrics['mae']:.4f}")

    with tab4:
        # è©•ä¼°æŒ‡æ¨™å¯è¦–åŒ–
        fig_metrics = st.session_state.visualizer.plot_metrics_comparison(
            st.session_state.metrics
        )
        st.plotly_chart(fig_metrics, use_container_width=True)

        # è©³ç´°è©•ä¼°å ±å‘Š
        st.subheader("è©³ç´°è©•ä¼°å ±å‘Š")

        metrics_df = pd.DataFrame({
            'æŒ‡æ¨™': ['RÂ² Score', 'Adjusted RÂ²', 'MSE', 'RMSE', 'MAE', 'MAPE (%)', 'SMAPE (%)'],
            'æ•¸å€¼': [
                f"{st.session_state.metrics['r2_score']:.4f}",
                f"{st.session_state.metrics['adjusted_r2']:.4f}",
                f"{st.session_state.metrics['mse']:.4f}",
                f"{st.session_state.metrics['rmse']:.4f}",
                f"{st.session_state.metrics['mae']:.4f}",
                f"{st.session_state.metrics['mape']:.2f}",
                f"{st.session_state.metrics['smape']:.2f}"
            ],
            'èªªæ˜': [
                'æ±ºå®šä¿‚æ•¸ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½',
                'èª¿æ•´å¾Œæ±ºå®šä¿‚æ•¸',
                'å‡æ–¹èª¤å·®ï¼Œè¶Šå°è¶Šå¥½',
                'å‡æ–¹æ ¹èª¤å·®ï¼Œè¶Šå°è¶Šå¥½',
                'å¹³å‡çµ•å°èª¤å·®ï¼Œè¶Šå°è¶Šå¥½',
                'å¹³å‡çµ•å°ç™¾åˆ†æ¯”èª¤å·®',
                'å°ç¨±å¹³å‡çµ•å°ç™¾åˆ†æ¯”èª¤å·®'
            ]
        })
        st.dataframe(metrics_df, use_container_width=True, hide_index=True)

if __name__ == "__main__":
    main()